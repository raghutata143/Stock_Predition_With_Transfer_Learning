{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code is to save S&P 500 Stock tickers\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# coding: utf8\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "import plotly\n",
    "import pickle\n",
    "import requests\n",
    "import warnings\n",
    "import bs4 as bs\n",
    "import math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.plotly as py\n",
    "from matplotlib import style\n",
    "import plotly.graph_objs as go\n",
    "import fix_yahoo_finance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MMM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ABT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ABBV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ABMD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ACN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ATVI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AYI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ADBE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AMD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AAP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AES\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AET\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AMG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AFL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing A\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing APD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AKAM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ALK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ALB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ARE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ALXN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ALGN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ALLE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AGN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ADS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LNT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ALL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GOOGL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GOOG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AMZN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AEE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AAL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AEP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AXP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AIG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AMT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AWK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AMP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ABC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AME\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AMGN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing APH\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing APC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ADI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ANDV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ANSS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ANTM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AON\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AOS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing APA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AIV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AAPL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AMAT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing APTV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ADM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ARNC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AJG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AIZ\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing T\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ADSK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ADP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AZO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AVB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AVY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BHGE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BLL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BAC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BAX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BBT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BDX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BRK.B\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BBY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BIIB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BLK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HRB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BKNG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BWA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BXP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BSX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BHF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BMY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing AVGO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BF.B\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CHRW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing COG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CDNS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CPB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing COF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CAH\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KMX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CCL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CAT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CBOE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CBRE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CBS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CELG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CNC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CNP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CTL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CERN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SCHW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CHTR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CVX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CMG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CHD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing XEC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CINF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CTAS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CSCO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing C\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CFG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CTXS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CLX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CME\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CMS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CTSH\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CMCSA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CMA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CAG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CXO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing COP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ED\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing STZ\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing COO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GLW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing COST\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing COTY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CCI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CSX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CMI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CVS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DHI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DHR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DRI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DVA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DAL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing XRAY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DVN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DLR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DFS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DISCA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DISCK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DISH\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DLTR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing D\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DOV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DWDP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DPS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DTE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DRE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DUK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DXC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ETFC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EMN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ETN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EBAY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ECL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EIX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EMR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ETR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EVHC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EOG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EQT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EFX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EQIX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EQR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ESS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EVRG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ES\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EXC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EXPE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EXPD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ESRX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing EXR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing XOM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FFIV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FAST\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FRT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FDX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FIS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FITB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FISV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FLIR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FLS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FLR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FMC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing F\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FTV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FBHS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing BEN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing FCX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GPS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GRMN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GGP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GIS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GPC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GILD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GPN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing GWW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HAL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HBI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HOG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HRS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HIG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HAS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HCA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HCP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HSIC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HSY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HES\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HPE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HLT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HOLX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HON\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HRL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HST\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HPQ\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HUM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HBAN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing HII\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IDXX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing INFO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ITW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ILMN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing INTC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ICE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IBM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing INCY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IPG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IFF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing INTU\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ISRG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IVZ\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IPGP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IQV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing IRM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing JEC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing JBHT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing JEF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SJM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing JNJ\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing JCI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing JPM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing JNPR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KSU\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing K\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KEY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KMB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KIM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KMI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KLAC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KSS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KHC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LLL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LH\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LRCX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LEG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LEN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LLY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LNC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LKQ\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LMT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing L\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LOW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LYB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MTB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MAC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing M\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MRO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MPC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MAR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MMC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MLM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MAS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MAT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MKC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MCD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MCK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MDT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MRK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MET\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MTD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MGM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing KORS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MCHP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MU\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MSFT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MAA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MHK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing TAP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MDLZ\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MNST\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MCO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MOS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MSI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MSCI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing MYL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NDAQ\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NOV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NKTR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NTAP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NFLX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NWL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NFX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NEM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NWSA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NWS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NEE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NLSN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NKE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NBL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing JWN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NSC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NTRS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NOC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NCLH\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NRG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NUE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing NVDA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ORLY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing OXY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing OMC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing OKE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ORCL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PCAR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PKG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PH\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PAYX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PYPL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PNR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PBCT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PEP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PKI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PRGO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PFE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PCG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PSX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PNW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PXD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PNC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PPG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PPL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PFG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PGR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PLD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PRU\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PEG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PSA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PHM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PVH\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing QRVO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing PWR\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing QCOM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing DGX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RRC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RJF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RTN\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing O\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RHT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing REG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing REGN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RSG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RMD\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RHI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ROK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing COL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ROP\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing ROST\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing RCL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing CRM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SBAC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SCG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SLB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing STX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SEE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SRE\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SHW\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SPG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SWKS\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SLG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SNA\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SO\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing LUV\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SPGI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SWK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SBUX\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing STT\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SRCL\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SYK\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing STI\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SIVB\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SYMC\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='finance.yahoo.com', port=443): Max retries exceeded with url: /quote/SPY/history (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001A0DD5D9208>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 141\u001b[1;33m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 150\u001b[1;33m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x000001A0DD5D9208>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 )\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 639\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='finance.yahoo.com', port=443): Max retries exceeded with url: /quote/SPY/history (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001A0DD5D9208>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ab544f82d10a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Already have {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mget_data_from_yahoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-ab544f82d10a>\u001b[0m in \u001b[0;36mget_data_from_yahoo\u001b[1;34m(reload_sp500)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Parsing\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stock_dfs/{}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stock_dfs/{}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\fix_yahoo_finance\\__init__.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, as_panel, group_by, auto_adjust, progress, actions, threads, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m         download_chunk(tickers, start=start, end=end,\n\u001b[0;32m    168\u001b[0m                        \u001b[0mauto_adjust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauto_adjust\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                        actions=actions, **kwargs)\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;31m# threaded download\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\fix_yahoo_finance\\__init__.py\u001b[0m in \u001b[0;36mdownload_chunk\u001b[1;34m(tickers, start, end, auto_adjust, progress, actions, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;31m# yahoo crumb/cookie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# crumb, cookie = get_yahoo_crumb()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mget_yahoo_crumb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mtried_once\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\fix_yahoo_finance\\__init__.py\u001b[0m in \u001b[0;36mget_yahoo_crumb\u001b[1;34m(force)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_YAHOO_CRUMB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_YAHOO_COOKIE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_requests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://finance.yahoo.com/quote/SPY/history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0m_YAHOO_COOKIE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    506\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='finance.yahoo.com', port=443): Max retries exceeded with url: /quote/SPY/history (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001A0DD5D9208>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))"
     ]
    }
   ],
   "source": [
    "# # saving sp500 tickers from sp500 list of companines\n",
    "# def save_sp500_tickers():\n",
    "#     resp = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "#     soup = bs.BeautifulSoup(resp.text)\n",
    "#     table = soup.find('table',{'class':'wikitable sortable'})\n",
    "#     tickers = []\n",
    "#     for row in table.findAll('tr')[1:]:\n",
    "#         ticker = row.findAll('td')[0].text\n",
    "#         tickers.append(ticker)\n",
    "        \n",
    "#     with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "#         pickle.dump(tickers, f)\n",
    "#         print(tickers)\n",
    "#         return tickers\n",
    "\n",
    "# # save_sp500_tickers() -- This returns all the tickers from S&P 500 Data\n",
    "\n",
    "# def get_data_from_yahoo(reload_sp500=False):\n",
    "#     if reload_sp500:\n",
    "#         tickers = save_sp500_tickers()\n",
    "#     else:\n",
    "#         with open(\"sp500tickers.pickle\",\"rb\") as f:\n",
    "#             tickers = pickle.load(f)\n",
    "        \n",
    "#     if not os.path.exists('stock_dfs'):\n",
    "#         os.makedirs('stock_dfs')\n",
    "        \n",
    "#     start_date = dt.datetime(2010,1,1)\n",
    "#     end_date = dt.datetime(2018,5,31)\n",
    "    \n",
    "#     #This function is to get the data of all the tickers (500)\n",
    "#     for ticker in tickers:\n",
    "#         print(\"Parsing\",ticker)\n",
    "#         if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "#             df = yf.download(ticker,start_date, end_date)\n",
    "#             df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "#             time.sleep(22)\n",
    "#         else:\n",
    "#             print('Already have {}'.format(ticker))\n",
    "\n",
    "# get_data_from_yahoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = yf.download('EVRG',start_date, end_date)\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing EVRG\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SNPS\n",
      "Already have SNPS\n",
      "Parsing SYF\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SYMC\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing SYY\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "Parsing XOM\n",
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    }
   ],
   "source": [
    "# # Funtion to retreive missing tickers data\n",
    "# tickers = ['EVRG','SNPS','SYF','SYMC','SYY','XOM']\n",
    "\n",
    "\n",
    "# def missing_data():        \n",
    "#     if not os.path.exists('stock_dfs'):\n",
    "#         os.makedirs('stock_dfs')\n",
    "        \n",
    "#     start_date = dt.datetime(2010,1,1)\n",
    "#     end_date = dt.datetime(2018,5,31)\n",
    "    \n",
    "#     #This function is to get the data of all the tickers (500)\n",
    "#     for ticker in tickers:\n",
    "#         print(\"Parsing\",ticker)\n",
    "#         if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "#             df = yf.download(ticker,start_date, end_date)\n",
    "#             df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "#             time.sleep(22)\n",
    "#         else:\n",
    "#             print('Already have {}'.format(ticker))\n",
    "\n",
    "# missing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "                  MMM        ABT  ABBV  ABMD        ACN       ATVI        AYI  \\\n",
      "Date                                                                            \n",
      "2009-12-31  66.870346  18.608963   NaN  8.73  34.275032  10.102340  33.853912   \n",
      "2010-01-04  67.153427  18.770958   NaN  8.74  34.745800  10.275106  34.224380   \n",
      "2010-01-05  66.732811  18.619303   NaN  8.53  34.960529  10.293294  34.509338   \n",
      "2010-01-06  67.679230  18.722702   NaN  8.40  35.332191  10.238736  35.003288   \n",
      "2010-01-07  67.727753  18.877800   NaN  8.40  35.299152   9.993223  36.095654   \n",
      "\n",
      "                 ADBE   AMD        AAP ...        WYNN        XEL  XRX  \\\n",
      "Date                                   ...                               \n",
      "2009-12-31  36.779999  9.68  39.608784 ...   43.206295  15.368580  NaN   \n",
      "2010-01-04  37.090000  9.70  39.510929 ...   47.457897  15.267188  NaN   \n",
      "2010-01-05  37.700001  9.71  39.276093 ...   50.344254  15.086126  NaN   \n",
      "2010-01-06  37.619999  9.57  39.618572 ...   49.683880  15.115088  NaN   \n",
      "2010-01-07  36.889999  9.47  39.608784 ...   50.744930  15.049910  NaN   \n",
      "\n",
      "                 XLNX         XL  XYL        YUM        ZBH       ZION  ZTS  \n",
      "Date                                                                         \n",
      "2009-12-31  20.342655  15.397597  NaN  19.994463  55.736500  12.181588  NaN  \n",
      "2010-01-04  20.602419  15.725214  NaN  20.063066  56.594555  12.656321  NaN  \n",
      "2010-01-05  20.342655  15.616008  NaN  19.994463  58.386120  13.102568  NaN  \n",
      "2010-01-06  20.204662  15.456399  NaN  19.851519  58.367264  14.241924  NaN  \n",
      "2010-01-07  20.001724  15.456399  NaN  19.845798  59.706226  15.837014  NaN  \n",
      "\n",
      "[5 rows x 505 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Joing all stocks closing prices\n",
    "\n",
    "# def compile_data():\n",
    "#     with open(\"sp500tickers.pickle\",\"rb\") as f:\n",
    "#         tickers = pickle.load(f)\n",
    "        \n",
    "        \n",
    "#     main_df = pd.DataFrame()\n",
    "    \n",
    "#     for count,ticker in enumerate(tickers):\n",
    "#         df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "#         df.Date = pd.to_datetime(df.Date)\n",
    "#         df.set_index('Date', inplace=True)\n",
    "#         df.rename(columns = {'Adj Close': ticker}, inplace = True)\n",
    "#         df.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis = 1, inplace = True)\n",
    "        \n",
    "#         if main_df.empty:\n",
    "#             main_df = df\n",
    "            \n",
    "#         else:\n",
    "#             main_df = main_df.join(df, how = 'outer')\n",
    "            \n",
    "#         if count % 10 == 0: # if count = 0, then print the count\n",
    "#             print(count)\n",
    "            \n",
    "            \n",
    "#     print(main_df.head())\n",
    "#     main_df.to_csv('sp500_joined_closing_prices.csv')\n",
    "    \n",
    "# compile_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~raghu.tata143/22.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting OHLC Plot of 3 stocks for visualization\n",
    "\n",
    "apple = yf.download('aapl', start_date, end_date).reset_index()\n",
    "google = yf.download('goog', start_date, end_date).reset_index()\n",
    "msft = yf.download('msft', start_date, end_date).reset_index()\n",
    "\n",
    "apple = go.Ohlc(x=apple.Date,\n",
    "                open=apple.Open,\n",
    "                high=apple.High,\n",
    "                low=apple.Low,\n",
    "                close=apple.Close,\n",
    "                name = \"Apple\",\n",
    "                increasing=dict(line=dict(color= '#17BECF')),\n",
    "                decreasing=dict(line=dict(color= '#7F7F7F')))\n",
    "\n",
    "google = go.Ohlc(x=google.Date,\n",
    "                open=google.Open,\n",
    "                high=google.High,\n",
    "                low=google.Low,\n",
    "                close=google.Close,\n",
    "                name = \"Google\", \n",
    "                increasing=dict(line=dict(color= '#FF5733')),\n",
    "                decreasing=dict(line=dict(color= '#C16627')))\n",
    "                   \n",
    "msft = go.Ohlc(x=msft.Date,\n",
    "                open=msft.Open,\n",
    "                high=msft.High,\n",
    "                low=msft.Low,\n",
    "                close=msft.Close,\n",
    "                name = \"Microsoft\",\n",
    "                increasing=dict(line=dict(color= '#78E324')),\n",
    "                decreasing=dict(line=dict(color= '#2441E3')))\n",
    "                   \n",
    "layout = dict(title='S&P Stocks OHLC Curve from 2010 to 2018',xaxis=dict(title='Time Step',\n",
    "            titlefont=dict(family='Courier New, monospace',size=18,color='#7f7f7f')),\n",
    "            yaxis=dict(title='Price',titlefont=dict(family='Courier New, monospace',size=18,color='#7f7f7f')))\n",
    "\n",
    "data = [apple, google, msft]\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "py.iplot(fig, filename='styled_ohlc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~raghu.tata143/24.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_data():\n",
    "    df = pd.read_csv('sp500_joined_closing_prices.csv')\n",
    "    df_corr = df.corr()\n",
    "    data = df_corr.values\n",
    "    column_labels = df_corr.columns\n",
    "    row_labels = df_corr.index\n",
    "\n",
    "    data = [go.Heatmap(z = data, x =  column_labels, y = row_labels, colorscale='Viridis')]\n",
    "\n",
    "    layout = go.Layout(title='Heatmaps',\n",
    "    xaxis = dict(ticks='', nticks=36),\n",
    "    yaxis = dict(ticks='' ))\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return py.iplot(fig, filename='datetime-heatmap')\n",
    "    \n",
    "    \n",
    "visualize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
