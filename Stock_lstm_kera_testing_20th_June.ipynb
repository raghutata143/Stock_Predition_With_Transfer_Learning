{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.cross_validation import  train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MMM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>...</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XL</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>66.870346</td>\n",
       "      <td>18.608963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.73</td>\n",
       "      <td>34.275032</td>\n",
       "      <td>10.102340</td>\n",
       "      <td>36.779999</td>\n",
       "      <td>9.68</td>\n",
       "      <td>39.608784</td>\n",
       "      <td>...</td>\n",
       "      <td>43.206295</td>\n",
       "      <td>15.368580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.342655</td>\n",
       "      <td>15.397597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.994463</td>\n",
       "      <td>55.736500</td>\n",
       "      <td>12.181588</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>67.153427</td>\n",
       "      <td>18.770958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.74</td>\n",
       "      <td>34.745800</td>\n",
       "      <td>10.275106</td>\n",
       "      <td>37.090000</td>\n",
       "      <td>9.70</td>\n",
       "      <td>39.510929</td>\n",
       "      <td>...</td>\n",
       "      <td>47.457897</td>\n",
       "      <td>15.267188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.602419</td>\n",
       "      <td>15.725214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.063066</td>\n",
       "      <td>56.594555</td>\n",
       "      <td>12.656321</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>66.732811</td>\n",
       "      <td>18.619303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.53</td>\n",
       "      <td>34.960529</td>\n",
       "      <td>10.293294</td>\n",
       "      <td>37.700001</td>\n",
       "      <td>9.71</td>\n",
       "      <td>39.276093</td>\n",
       "      <td>...</td>\n",
       "      <td>50.344254</td>\n",
       "      <td>15.086126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.342655</td>\n",
       "      <td>15.616008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.994463</td>\n",
       "      <td>58.386120</td>\n",
       "      <td>13.102568</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>67.679230</td>\n",
       "      <td>18.722702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.40</td>\n",
       "      <td>35.332191</td>\n",
       "      <td>10.238736</td>\n",
       "      <td>37.619999</td>\n",
       "      <td>9.57</td>\n",
       "      <td>39.618572</td>\n",
       "      <td>...</td>\n",
       "      <td>49.683880</td>\n",
       "      <td>15.115088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.204662</td>\n",
       "      <td>15.456399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.851519</td>\n",
       "      <td>58.367264</td>\n",
       "      <td>14.241924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>67.727753</td>\n",
       "      <td>18.877800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.40</td>\n",
       "      <td>35.299152</td>\n",
       "      <td>9.993223</td>\n",
       "      <td>36.889999</td>\n",
       "      <td>9.47</td>\n",
       "      <td>39.608784</td>\n",
       "      <td>...</td>\n",
       "      <td>50.744930</td>\n",
       "      <td>15.049910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.001724</td>\n",
       "      <td>15.456399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.845798</td>\n",
       "      <td>59.706226</td>\n",
       "      <td>15.837014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        MMM        ABT  ABBV  ABMD        ACN       ATVI  \\\n",
       "0  2009-12-31  66.870346  18.608963   NaN  8.73  34.275032  10.102340   \n",
       "1  2010-01-04  67.153427  18.770958   NaN  8.74  34.745800  10.275106   \n",
       "2  2010-01-05  66.732811  18.619303   NaN  8.53  34.960529  10.293294   \n",
       "3  2010-01-06  67.679230  18.722702   NaN  8.40  35.332191  10.238736   \n",
       "4  2010-01-07  67.727753  18.877800   NaN  8.40  35.299152   9.993223   \n",
       "\n",
       "        ADBE   AMD        AAP ...        WYNN        XEL  XRX       XLNX  \\\n",
       "0  36.779999  9.68  39.608784 ...   43.206295  15.368580  NaN  20.342655   \n",
       "1  37.090000  9.70  39.510929 ...   47.457897  15.267188  NaN  20.602419   \n",
       "2  37.700001  9.71  39.276093 ...   50.344254  15.086126  NaN  20.342655   \n",
       "3  37.619999  9.57  39.618572 ...   49.683880  15.115088  NaN  20.204662   \n",
       "4  36.889999  9.47  39.608784 ...   50.744930  15.049910  NaN  20.001724   \n",
       "\n",
       "          XL  XYL        YUM        ZBH       ZION  ZTS  \n",
       "0  15.397597  NaN  19.994463  55.736500  12.181588  NaN  \n",
       "1  15.725214  NaN  20.063066  56.594555  12.656321  NaN  \n",
       "2  15.616008  NaN  19.994463  58.386120  13.102568  NaN  \n",
       "3  15.456399  NaN  19.851519  58.367264  14.241924  NaN  \n",
       "4  15.456399  NaN  19.845798  59.706226  15.837014  NaN  \n",
       "\n",
       "[5 rows x 506 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "\n",
    "#load the dataset\n",
    "stock_dataset = pd.read_csv('sp500_joined_closing_prices.csv')\n",
    "stock_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date      object\n",
       "MMM      float64\n",
       "ABT      float64\n",
       "ABBV     float64\n",
       "ABMD     float64\n",
       "ACN      float64\n",
       "ATVI     float64\n",
       "ADBE     float64\n",
       "AMD      float64\n",
       "AAP      float64\n",
       "AES      float64\n",
       "AET      float64\n",
       "AMG      float64\n",
       "AFL      float64\n",
       "A        float64\n",
       "APD      float64\n",
       "AKAM     float64\n",
       "ALK      float64\n",
       "ALB      float64\n",
       "ARE      float64\n",
       "ALXN     float64\n",
       "ALGN     float64\n",
       "ALLE     float64\n",
       "AGN      float64\n",
       "ADS      float64\n",
       "LNT      float64\n",
       "ALL      float64\n",
       "GOOGL    float64\n",
       "GOOG     float64\n",
       "MO       float64\n",
       "          ...   \n",
       "VRTX     float64\n",
       "VIAB     float64\n",
       "V        float64\n",
       "VNO      float64\n",
       "VMC      float64\n",
       "WMT      float64\n",
       "WBA      float64\n",
       "DIS      float64\n",
       "WM       float64\n",
       "WAT      float64\n",
       "WEC      float64\n",
       "WFC      float64\n",
       "WELL     float64\n",
       "WDC      float64\n",
       "WU       float64\n",
       "WRK      float64\n",
       "WY       float64\n",
       "WHR      float64\n",
       "WMB      float64\n",
       "WLTW     float64\n",
       "WYNN     float64\n",
       "XEL      float64\n",
       "XRX      float64\n",
       "XLNX     float64\n",
       "XL       float64\n",
       "XYL      float64\n",
       "YUM      float64\n",
       "ZBH      float64\n",
       "ZION     float64\n",
       "ZTS      float64\n",
       "Length: 506, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2117 entries, 2009-12-31 to 2018-05-30\n",
      "Columns: 505 entries, MMM to ZTS\n",
      "dtypes: float64(505)\n",
      "memory usage: 8.2 MB\n"
     ]
    }
   ],
   "source": [
    "stock_dataset['Date'] = pd.to_datetime(stock_dataset['Date'])\n",
    "\n",
    "stock_dataset.set_index('Date',inplace=True)\n",
    "stock_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dataset.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 66.870346,  18.608963,   0.      , ...,  55.7365  ,  12.181588,\n",
       "          0.      ],\n",
       "       [ 67.153427,  18.770958,   0.      , ...,  56.594555,  12.656321,\n",
       "          0.      ],\n",
       "       [ 66.732811,  18.619303,   0.      , ...,  58.38612 ,  13.102568,\n",
       "          0.      ],\n",
       "       ...,\n",
       "       [199.029999,  62.369999, 101.080002, ..., 111.080002,  57.049999,\n",
       "         83.669998],\n",
       "       [195.740005,  61.299999,  99.470001, ..., 109.269997,  54.919998,\n",
       "         83.150002],\n",
       "       [198.679993,  62.07    , 103.010002, ..., 110.650002,  55.529999,\n",
       "         84.449997]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "stock_dataset = stock_dataset.values\n",
    "stock_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03541255, 0.04842943, 0.        , ..., 0.13083924, 0.        ,\n",
       "        0.        ],\n",
       "       [0.03686115, 0.05187748, 0.        , ..., 0.14064667, 0.01024049,\n",
       "        0.        ],\n",
       "       [0.03470875, 0.04864951, 0.        , ..., 0.16112398, 0.01986651,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.71170733, 0.97988079, 0.82888569, ..., 0.76340681, 0.96785908,\n",
       "        0.97467495],\n",
       "       [0.69487159, 0.95710589, 0.81568321, ..., 0.74271874, 0.92191271,\n",
       "        0.96861749],\n",
       "       [0.70991626, 0.97349532, 0.84471225, ..., 0.75849198, 0.93507107,\n",
       "        0.98376118]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_close = scaler.fit_transform(stock_dataset)\n",
    "stock_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into train and test:  1481 636\n"
     ]
    }
   ],
   "source": [
    "#split data into train and test\n",
    "train_size = int(len(stock_close)* 0.7)\n",
    "test_size = len(stock_close) - train_size\n",
    "\n",
    "stock_train, stock_test = stock_close[0:train_size, :], stock_close[train_size:len(stock_close), :]\n",
    "\n",
    "print('Split data into train and test: ', len(stock_train), len(stock_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to now convert the data into time series looking back over a period of days...e.g. use last 7 days to predict price\n",
    "\n",
    "def create_ts(ds, series):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(ds)-series - 1):\n",
    "        item = ds[i:(i+series), 0]\n",
    "        X.append(item)\n",
    "        Y.append(ds[i+series, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "series = 7\n",
    "\n",
    "trainX, trainY = create_ts(stock_train, series)\n",
    "testX, testY = create_ts(stock_test, series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03541255, 0.03686115, 0.03470875, ..., 0.03980012, 0.04224225,\n",
       "        0.04083507],\n",
       "       [0.03686115, 0.03470875, 0.03955182, ..., 0.04224225, 0.04083507,\n",
       "        0.04112465],\n",
       "       [0.03470875, 0.03955182, 0.03980012, ..., 0.04083507, 0.04112465,\n",
       "        0.04000708],\n",
       "       ...,\n",
       "       [0.45150014, 0.45226441, 0.45264671, ..., 0.44538615, 0.44595928,\n",
       "        0.4529332 ],\n",
       "       [0.45226441, 0.45264671, 0.4539361 , ..., 0.44595928, 0.4529332 ,\n",
       "        0.43979759],\n",
       "       [0.45264671, 0.4539361 , 0.44538615, ..., 0.4529332 , 0.43979759,\n",
       "        0.43669269]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03541255, 0.03686115, 0.03470875, 0.03955182, 0.03980012,\n",
       "       0.04224225, 0.04083507])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1473, 7, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape into  LSTM format - samples, steps, features\n",
    "# trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 503))\n",
    "# testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 503))\n",
    "\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_3_input to have shape (7, 503) but got array with shape (7, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ad227418973f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1631\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_3_input to have shape (7, 503) but got array with shape (7, 1)"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(series, 503)))\n",
    "model.add(Dense(503))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "#fit the model\n",
    "model.fit(trainX, trainY, epochs=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1473,1) doesn't match the broadcast shape (1473,505)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-156b6f2a1f06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtestPredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#unscale predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrainPredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainPredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtestPredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestPredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEPRECATION_MSG_1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1473,1) doesn't match the broadcast shape (1473,505)"
     ]
    }
   ],
   "source": [
    "#test this model out\n",
    "trainPredictions = model.predict(trainX)\n",
    "testPredictions = model.predict(testX)\n",
    "#unscale predictions\n",
    "trainPredictions = scaler.inverse_transform(trainPredictions)\n",
    "testPredictions = scaler.inverse_transform(testPredictions)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 0.041124648618500514 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ee7f9a2ddce9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#lets calculate the root mean squared error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainPredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtestScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestPredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train score: %.2f rmse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test score: %.2f rmse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 231\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    232\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[0;32m    233\u001b[0m                                weights=sample_weight)\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \"\"\"\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \"\"\"\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 126\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 0.041124648618500514 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "#lets calculate the root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredictions[:, 0]))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredictions[:, 0]))\n",
    "print('Train score: %.2f rmse', trainScore)\n",
    "print('Test score: %.2f rmse', testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
